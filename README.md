To run the code, first ensure you have the necessary Python libraries installed, including pandas, numpy, sklearn, and imblearn. 
The dataset is loaded from a local CSV file, and the code begins with data preprocessing steps such as handling missing values, encoding categorical features, and splitting the data into training and testing sets. 
SMOTE is applied to balance the classes in the training data. 
The key components of the project include the use of three classification algorithms—Logistic Regression, Decision Tree, and Random Forest—along with model evaluation using accuracy, precision, recall, and F1 score. 
The notebook also contains code to adjust classification thresholds and tune hyperparameters for improved model performance. 
This workflow allows for a full machine learning pipeline from raw data to performance evaluation.
